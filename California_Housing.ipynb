{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEkDOHtXAPGB"
      },
      "outputs": [],
      "source": [
        " # ======================================================\n",
        "# 1) Introdução\n",
        "# ======================================================\n",
        "# Este notebook foi preparado para ser executado no Google Colab.\n",
        "# Objetivo: treinar um modelo de Machine Learning (ex.: Rede Neural)\n",
        "# para prever o valor mediano de casas na Califórnia.\n",
        "#\n",
        "# Dataset: California Housing (scikit-learn)\n",
        "#\n",
        "# Fluxo:\n",
        "#   1. Carregar dataset\n",
        "#   2. Dividir em treino/teste\n",
        "#   3. Pré-processamento com ColumnTransformer\n",
        "#   4. Baseline com DummyRegressor\n",
        "#   5. Treinar seu modelo de ML (ex.: Rede Neural MLP)\n",
        "#   6. Avaliar métricas (MAE, RMSE, R²)\n",
        "#   7. Adicione PCA ao código e treine novamente o modelo de Rede Neural.\n",
        "\n",
        "#Cayque siquera mantesso\n",
        "#Paulo Vitor Freitas da Costa\n",
        "#Lucas Ribeiro Goulart\n",
        "#Pedro Allan Chiarelli"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# 2) Imports e Configurações\n",
        "# ======================================================\n",
        "\n",
        "import os\n",
        "import random\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Semente para reprodutibilidade\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n"
      ],
      "metadata": {
        "id": "VfJua3QmAa3W"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# 3) Funções Auxiliares\n",
        "# ======================================================\n",
        "\n",
        "def load_california_housing():\n",
        "    \"\"\"\n",
        "    Carrega o dataset California Housing como DataFrame.\n",
        "    Retorna X, y, lista de colunas numéricas e categóricas.\n",
        "    \"\"\"\n",
        "    ds = fetch_california_housing(as_frame=True)\n",
        "    frame = ds.frame.copy()\n",
        "    y = frame[\"MedHouseVal\"]\n",
        "    X = frame.drop(columns=[\"MedHouseVal\"])\n",
        "    numeric_features = X.columns.tolist()\n",
        "    categorical_features = []  # não há colunas categóricas\n",
        "    return X, y, numeric_features, categorical_features\n",
        "\n",
        "\n",
        "def build_preprocessor(numeric_features, categorical_features):\n",
        "    \"\"\"\n",
        "    Cria o pré-processador:\n",
        "      - Numéricas: imputação de mediana + padronização\n",
        "      - Categóricas: (não usado aqui, mas estrutura mantida para exemplos futuros)\n",
        "    \"\"\"\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_transformer, numeric_features),\n",
        "        ]\n",
        "    )\n",
        "    return preprocessor\n",
        "\n",
        "\n",
        "def evaluate(model, X_test, y_test, label=\"Modelo\"):\n",
        "    \"\"\"\n",
        "    Avalia o modelo no conjunto de teste e retorna métricas (MAE, RMSE, R²).\n",
        "    Compatível com versões antigas do scikit-learn.\n",
        "    \"\"\"\n",
        "    preds = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))  # corrigido\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    print(f\"[{label}]  MAE={mae:.4f} | RMSE={rmse:.4f} | R²={r2:.4f}\")\n",
        "    return {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
        "\n"
      ],
      "metadata": {
        "id": "UIrDHQWEAddn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# 4) Carregar Dados e Split\n",
        "# ======================================================\n",
        "\n",
        "X, y, num_feats, cat_feats = load_california_housing()\n",
        "print(f\"Dataset carregado. X shape={X.shape} | y shape={y.shape}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=RANDOM_SEED\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-ZxO1MJnAhPg",
        "outputId": "de68d4de-f342-4084-bae7-5a40c67b6edd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset carregado. X shape=(20640, 8) | y shape=(20640,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# 5) Baseline (DummyRegressor)\n",
        "# ======================================================\n",
        "\n",
        "preprocessor = build_preprocessor(num_feats, cat_feats)\n",
        "\n",
        "baseline = Pipeline(steps=[\n",
        "    (\"pre\", preprocessor),\n",
        "    (\"reg\", DummyRegressor(strategy=\"median\"))\n",
        "])\n",
        "\n",
        "baseline.fit(X_train, y_train)\n",
        "evaluate(baseline, X_test, y_test, label=\"Baseline (Dummy)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uVnJrZd0Ajwx",
        "outputId": "4ef6951f-a082-41fb-b255-725d820adc74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Baseline (Dummy)]  MAE=0.8740 | RMSE=1.1731 | R²=-0.0502\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MAE': 0.8740399224806202,\n",
              " 'RMSE': np.float64(1.1731167105035603),\n",
              " 'R2': -0.050208628996205595}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# 6) Seu Modelo de Machine Learning\n",
        "# ======================================================\n",
        "# Aqui você deve substituir pelo modelo que deseja treinar.\n",
        "# Sugestão: Rede Neural com MLPRegressor, Random Forest ou Regressão Linear Ridge.\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Pipeline com preprocessor, PCA e MLP\n",
        "model = Pipeline(steps=[\n",
        "    (\"pre\", preprocessor),\n",
        "    (\"pca\", PCA(n_components=7, random_state=RANDOM_SEED)),\n",
        "    (\"reg\", MLPRegressor(hidden_layer_sizes=(12, 12),\n",
        "                         activation=\"tanh\",\n",
        "                         learning_rate_init=0.001,\n",
        "                         max_iter=1500,\n",
        "                         random_state=RANDOM_SEED))\n",
        "])\n",
        "\n",
        "# Validação cruzada (5-fold)\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"r2\")\n",
        "print(f\"Validação Cruzada R² (média ± desvio): {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
        "\n",
        "# Treino final\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Previsões no treino e teste\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Avaliação dos conjuntos\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def print_metrics(y_true, y_pred, label):\n",
        "    print(f\"\\n=== {label} ===\")\n",
        "    print(f\"R²: {r2_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"MAE: {mean_absolute_error(y_true, y_pred):.4f}\")\n",
        "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_true, y_pred)):.4f}\")\n",
        "\n",
        "print_metrics(y_train, y_train_pred, \"Treino\")\n",
        "print_metrics(y_test, y_test_pred, \"Teste\")\n",
        "\n",
        "metrics = evaluate(model, X_test, y_test, label=\"Rede Neural (MLP + PCA)\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0CZ_T6lAodW",
        "outputId": "4c0d652b-5e1c-43b4-f85a-ce3babf7e1a8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validação Cruzada R² (média ± desvio): 0.7540 ± 0.0060\n",
            "\n",
            "=== Treino ===\n",
            "R²: 0.7674\n",
            "MAE: 0.3849\n",
            "RMSE: 0.5576\n",
            "\n",
            "=== Teste ===\n",
            "R²: 0.7467\n",
            "MAE: 0.3948\n",
            "RMSE: 0.5761\n",
            "[Rede Neural (MLP + PCA)]  MAE=0.3948 | RMSE=0.5761 | R²=0.7467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# 7) Salvando Artefatos no Colab\n",
        "# ======================================================\n",
        "\n",
        "# Criar diretório para salvar resultados\n",
        "os.makedirs(\"artifacts\", exist_ok=True)\n",
        "\n",
        "# Salvar modelo treinado\n",
        "joblib.dump(model, \"artifacts/model_california.joblib\")\n",
        "\n",
        "# Salvar métricas em arquivo texto\n",
        "with open(\"artifacts/metrics.txt\", \"w\") as f:\n",
        "    for k, v in metrics.items():\n",
        "        f.write(f\"{k}: {v}\\n\")\n",
        "\n",
        "print(\"✅ Artefatos salvos em ./artifacts\")\n"
      ],
      "metadata": {
        "id": "xO12pEdvAvUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a348d625-6ca0-4ff2-d1e6-7f8ac9fd65f0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Artefatos salvos em ./artifacts\n"
          ]
        }
      ]
    }
  ]
}
